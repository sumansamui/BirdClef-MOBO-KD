{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T08:39:30.970863Z",
     "iopub.status.busy": "2025-07-13T08:39:30.970550Z",
     "iopub.status.idle": "2025-07-13T08:39:31.262579Z",
     "shell.execute_reply": "2025-07-13T08:39:31.261319Z",
     "shell.execute_reply.started": "2025-07-13T08:39:30.970843Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n",
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining bird class species for classification\n",
    "\n",
    "10 specific bird species and one 'others' class containing birdcall audio from 397 different birds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T10:27:34.785516Z",
     "iopub.status.busy": "2025-07-13T10:27:34.785059Z",
     "iopub.status.idle": "2025-07-13T10:27:34.832566Z",
     "shell.execute_reply": "2025-07-13T10:27:34.831679Z",
     "shell.execute_reply.started": "2025-07-13T10:27:34.785458Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class_names = ['redcro', 'norcar', 'comrav', 'houspa', 'barswa', 'houwre', 'sonspa', 'gbwwre1', 'eursta', 'spotow']\n",
    "class_names.append('others')\n",
    "class_label_files = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_directory = r'C:/Users/B.B GHOSH//Desktop/kaggle_input/kaggle/input/birdclef-2021/train_short_audio/'\n",
    "for bird_name in bird_names:\n",
    "    bird_directory = os.path.join(base_directory, bird_name)\n",
    "    if os.path.exists(bird_directory) and os.path.isdir(bird_directory):\n",
    "        # Get list of files in the bird directory\n",
    "        bird_files = os.listdir(bird_directory)\n",
    "        # Store the list of files in the dictionary under the bird name key\n",
    "        bird_label_files[bird_name] = [os.path.join(bird_directory, file) for file in bird_files]\n",
    "bird_label_files.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Birdcall extraction\n",
    "\n",
    "The recorded raw audio files have captured the background environmental sounds alongwith the periods of bird call. We have used a percentile based SNR thrsholding in order to segregate timings of bird call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T10:27:59.859001Z",
     "iopub.status.busy": "2025-07-13T10:27:59.858638Z",
     "iopub.status.idle": "2025-07-13T10:27:59.872180Z",
     "shell.execute_reply": "2025-07-13T10:27:59.871086Z",
     "shell.execute_reply.started": "2025-07-13T10:27:59.858976Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_audio_info(file_path, window_duration=0.03):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path)\n",
    "        duration = librosa.get_duration(y=y, sr=sr)\n",
    "        num_samples = len(y)\n",
    "        window_samples = int(sr * window_duration)\n",
    "        num_windows = num_samples // window_samples\n",
    "        return y, sr, duration, num_samples, window_duration, window_samples, num_windows\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return None, None, None, None, None, None, None\n",
    "\n",
    "def calculate_windowed_snr(y, sr, num_samples, num_windows, window_samples, threshold=0.2):\n",
    "    SNR = []\n",
    "    window = np.hanning(window_samples)\n",
    "    for i in range(num_windows):\n",
    "        start_index = i * window_samples\n",
    "        end_index = min((i + 1) * window_samples, num_samples)\n",
    "        window_signal = y[start_index:end_index] * window\n",
    "        noise_level = np.mean(np.abs(window_signal)[np.abs(window_signal) < threshold])\n",
    "        window_max_amplitude = np.var(window_signal)\n",
    "        SNR_window = 20 * np.log10(window_max_amplitude / noise_level)\n",
    "        SNR.append(SNR_window)\n",
    "    return SNR\n",
    "\n",
    "def find_better_snr_indices(SNR):\n",
    "    better_SNR_indices = []\n",
    "    sorted_SNR = sorted(SNR, reverse=True)\n",
    "    top_half_SNR = sorted_SNR[:int(len(sorted_SNR)*0.8)]\n",
    "    mean_SNR = np.mean(top_half_SNR)\n",
    "    \n",
    "    for i, SNR_value in enumerate(SNR):\n",
    "        if SNR_value > mean_SNR:\n",
    "            better_SNR_indices.append(i)\n",
    "    return better_SNR_indices\n",
    "\n",
    "def find_better_sample_indices(num_samples, window_samples, better_SNR_indices):\n",
    "    window_start_indices = np.arange(0, num_samples, window_samples)\n",
    "    window_end_indices = window_start_indices + window_samples\n",
    "    window_end_indices[-1] = num_samples\n",
    "\n",
    "    better_SNR_samples_indices = []\n",
    "    for window_index in better_SNR_indices:\n",
    "        start_index = window_start_indices[window_index]\n",
    "        end_index = window_end_indices[window_index]\n",
    "        better_SNR_samples_indices.extend(range(start_index, end_index))\n",
    "\n",
    "    return better_SNR_samples_indices\n",
    "\n",
    "def extract_audio_with_better_snr(y, better_SNR_samples_indices):\n",
    "    new_audio = y[better_SNR_samples_indices]\n",
    "    return new_audio\n",
    "\n",
    "def get_audio(file_path, window_duration=0.03):\n",
    "    y, sr, duration, num_samples, window_duration, window_samples, num_windows = get_audio_info(file_path, window_duration)\n",
    "    if y is None:\n",
    "        return None, None, None\n",
    "    \n",
    "    SNR = calculate_windowed_snr(y, sr, num_samples, num_windows, window_samples)\n",
    "    better_SNR_indices = find_better_snr_indices(SNR)\n",
    "    better_SNR_samples_indices = find_better_sample_indices(num_samples, window_samples, better_SNR_indices)\n",
    "    new_audio = extract_audio_with_better_snr(y, better_SNR_samples_indices)\n",
    "    \n",
    "    return new_audio, y, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "file_path=bird_label_files['barswa'][75]\n",
    "new_audio,y,sr=get_audio(file_path)\n",
    "print(\"Playing original audio:\")\n",
    "display(Audio(data=y, rate=sr))\n",
    "print(\"Playing cleaned audio:\")\n",
    "display(Audio(data=new_audio, rate=sr))\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.waveshow(y, sr=sr,color=\"green\")\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Waveform Plot of original Audio File')\n",
    "plt.show()\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.waveshow(new_audio, sr=sr,color=\"green\")\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Waveform Plot of cleaner Audio File')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log-mel spectrogram creation for processed audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_logmelspec(file_path):\n",
    "    new_audio, _, sr = get_audio(file_path)\n",
    "    if new_audio is None or sr is None:\n",
    "        return None\n",
    "    segment_length = sr\n",
    "    num_segments = len(new_audio) // 24000\n",
    "    logmelspec_list = []\n",
    "    for i in range(num_segments):\n",
    "        start_sample = i * segment_length\n",
    "        end_sample = (i + 1) * segment_length\n",
    "        segment = new_audio[start_sample:end_sample]\n",
    "        if len(segment) < segment_length:\n",
    "            segment = np.pad(segment, (0, segment_length - len(segment)), mode='constant')\n",
    "        mel_spec = librosa.feature.melspectrogram(y=segment, sr=sr, n_fft=1024, n_mels=64)\n",
    "        log_mel_spec = librosa.power_to_db(mel_spec)\n",
    "        logmelspec_list.append(log_mel_spec.T)\n",
    "    return np.array(logmelspec_list) if logmelspec_list else None\n",
    "\n",
    "file_path = class_label_files['comrav'][75]\n",
    "logmelspec = get_logmelspec(file_path)\n",
    "print(\"Shape of log-mel spectrogram array:\", logmelspec.shape if logmelspec is not None else \"Invalid audio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating logmelspec for all files post extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class_logmelspec_dict = {}\n",
    "n_files = 500 #Max number of files in one class\n",
    "\n",
    "for class_name, file_paths in class_label_files.items():\n",
    "    class_logmelspecs = []\n",
    "\n",
    "    for file_path in tqdm(file_paths[:n_files], \n",
    "                         desc=f\"Processing {class_name}\",\n",
    "                         mininterval=0.5,  # Update every 0.5 seconds minimum\n",
    "                         maxinterval=1.0,  # Maximum time between updates\n",
    "                         smoothing=0.1):   # Smoothing factor for speed estimation\n",
    "        logmelspec = get_logmelspec(file_path)\n",
    "        if logmelspec is not None:\n",
    "            class_logmelspecs.append(np.array(logmelspec))\n",
    "    class_logmelspec_dict[class_name] = class_logmelspecs\n",
    "\n",
    "# Results summary\n",
    "for class_name, logmelspec_list in class_logmelspec_dict.items():\n",
    "    print(f\"Processed {len(logmelspec_list)}/{n_files} files for {class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_melspec_dict = {}\n",
    "\n",
    "for class_name, logmelspec_list in class_logmelspec_dict.items():\n",
    "    if logmelspec_list:\n",
    "        stacked_array = np.vstack(logmelspec_list)\n",
    "        stacked_melspec_dict[class_name] = stacked_array\n",
    "    else:\n",
    "        stacked_melspec_dict[class_name] = None\n",
    "\n",
    "for class_name, stacked_array in stacked_melspec_dict.items():\n",
    "    if stacked_array is not None:\n",
    "        print(f\"Class '{class_name}' stacked shape: {stacked_array.shape}\")\n",
    "    else:\n",
    "        print(f\"Class '{class_name}' has no valid spectrograms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X = np.vstack([stacked_melspec_dict[cls] for cls in class_names if stacked_melspec_dict[cls] is not None])\n",
    "y = np.concatenate([np.full((stacked_melspec_dict[cls].shape[0], 1), i) \n",
    "                   for i, cls in enumerate(class_names) \n",
    "                   if stacked_melspec_dict[cls] is not None])\n",
    "\n",
    "print(f\"Combined spectrograms shape: {X.shape}\")\n",
    "print(f\"Label array shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding extra channel for 3D CNN processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output_path = '/kaggle/working/melspec_data.h5'\n",
    "\n",
    "X_cnn = np.expand_dims(X, axis=-1)\n",
    "\n",
    "with h5py.File(output_path, 'w') as hf:\n",
    "    hf.create_dataset('X_train', data=X_cnn) \n",
    "    hf.create_dataset('y_train', data=y)\n",
    "    hf.create_dataset('classes', data=np.array(class_names, dtype='S'))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 2091745,
     "sourceId": 25954,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
